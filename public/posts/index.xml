<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Cola.Meng&#39;Blog</title>
    <link>http://localhost:1313/posts/</link>
    <description>Recent content in Posts on Cola.Meng&#39;Blog</description>
    <image>
      <title>Cola.Meng&#39;Blog</title>
      <url>http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- 0.127.0</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 05 Jun 2024 08:29:34 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LangChain示例</title>
      <link>http://localhost:1313/posts/langchain%E7%A4%BA%E4%BE%8B/</link>
      <pubDate>Wed, 05 Jun 2024 08:29:34 +0800</pubDate>
      <guid>http://localhost:1313/posts/langchain%E7%A4%BA%E4%BE%8B/</guid>
      <description>Conda环境
conda create -n langchain-env python=3.11 conda activate langchain-env 依赖项
pip install --upgrade langchain pip install -U langchain-community Python调用示例
import os from langchain_core.prompts import ChatPromptTemplate from langchain_core.output_parsers import StrOutputParser from langchain_core.runnables import RunnablePassthrough from langchain_community.llms import Tongyi # 设置环境变量 os.environ[&amp;#34;DASHSCOPE_API_KEY&amp;#34;] = &amp;#34;sk-xxx&amp;#34; if __name__ == &amp;#34;__main__&amp;#34;: # 初始化通义千问模型 model = Tongyi(model_name=&amp;#34;qwen-turbo&amp;#34;) prompt = ChatPromptTemplate.from_template( &amp;#34;Tell me a short joke about {topic}&amp;#34; ) output_parser = StrOutputParser() chain = ( {&amp;#34;topic&amp;#34;: RunnablePassthrough()} | prompt | model | output_parser ) print(chain.</description>
    </item>
  </channel>
</rss>
